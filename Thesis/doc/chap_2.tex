\Chapter{Background e Stato dell'Arte}


La segmentazione semantica di immagini mediche rappresenta una delle sfide più importanti nel campo della diagnostica assistita da computer. Questo compito, che consiste nel delineare con precisione strutture anatomiche o aree patologiche all’interno di immagini biomediche, ha un impatto diretto su applicazioni cliniche cruciali come la pianificazione chirurgica, il monitoraggio terapeutico e la radiomica. Nel contesto specifico della mammella, la segmentazione da immagini MRI 3D presenta peculiarità che la rendono particolarmente complessa, tra cui l’elevata variabilità anatomica tra pazienti, la presenza di artefatti tipici delle risonanze magnetiche e la necessità di bilanciare accuratezza e tempi di elaborazione quando si lavora con volumi tridimensionali ad alta risoluzione.

\Section{L’Evoluzione delle Tecniche di Segmentazione}

Prima dell’avvento del deep learning, la segmentazione di immagini mediche si basava principalmente su approcci tradizionali che, pur rappresentando soluzioni pionieristiche per l’epoca, presentavano limiti significativi. Tecniche come il thresholding e il region-growing, ad esempio, erano ampiamente utilizzate per la loro semplicità concettuale, ma risultavano estremamente sensibili alla qualità dell’immagine, fallendo spesso in presenza di rumore o basso contrasto tra i tessuti. Allo stesso modo, i deformable models, che cercavano di adattare contorni attivi alle strutture anatomiche, richiedevano un’inizializzazione manuale e faticavano a gestire la complessa morfologia della ghiandola mammaria.

Con l’introduzione delle reti neurali convoluzionali (CNN), il panorama della segmentazione medica è cambiato radicalmente. L’architettura U-Net, proposta nel 2015 da Ronneberger et al., ha rappresentato una svolta grazie alla sua struttura encoder-decoder e alle connessioni skip, che permettono di combinare informazioni a diversi livelli di risoluzione, preservando i dettagli spaziali fondamentali per una segmentazione precisa. Successivamente, la comunità scientifica ha sviluppato varianti sempre più avanzate, come la V-Net, ottimizzata per dati volumetrici, e il framework nnU-Net, in grado di adattarsi automaticamente alle caratteristiche di diversi dataset medici.

Negli ultimi anni, l’attenzione si è spostata verso i Transformers, modelli nati nell’ambito del Natural Language Processing e poi adattati con successo all’analisi di immagini. Architetture come TransUNet e Swin UNETR combinano la capacità delle CNN di estrarre features locali con il potere dei Transformers di modellare relazioni globali, offrendo prestazioni superiori in molti task di segmentazione. Tuttavia, questi modelli richiedono risorse computazionali elevate e grandi quantità di dati annotati, il che ne limenta ancora l’applicabilità in alcuni contesti clinici.


\Section{Strumenti e Dataset Moderni}
Oggi, lo sviluppo di pipeline per la segmentazione medica si avvale di strumenti sempre più sofisticati. Tra questi, il framework MONAI (Medical Open Network for AI) si è affermato come uno standard de facto, grazie alla sua vasta raccolta di trasformazioni specifiche per immagini mediche, modelli predefiniti e metriche di valutazione. Basato su PyTorch, MONAI semplifica notevolmente la gestione di dati complessi come quelli DICOM e supporta l’implementazione di workflow riproducibili, essenziali per la ricerca in ambito medico.

Per quanto riguarda i dataset, il Duke-Breast-Cancer-MRI, disponibile su The Cancer Imaging Archive (TCIA), rappresenta una risorsa preziosa per lo studio della segmentazione mammaria. Questo dataset include volumi MRI multiparametrici annotati manualmente da radiologi esperti, catturando tutta la complessità anatomica e le sfide tipiche delle immagini reali, come la presenza di lesioni e la variabilità nella densità del tessuto.

\Section{Le Sfide Aperte}
Nonostante i progressi compiuti, la segmentazione del seno in MRI 3D presenta ancora diverse criticità. Una delle principali è la scarsità di dataset pubblici di grandi dimensioni, soprattutto se confrontata con la disponibilità di dati per altri organi come il cervello o il fegato. Inoltre, i modelli esistenti faticano spesso a generalizzare su dati provenienti da diversi centri medici, a causa delle variazioni tra scanner e protocolli di acquisizione.

Un altro aspetto critico è l’integrazione di questi strumenti nei workflow clinici quotidiani. Molti modelli, pur offrendo prestazioni elevate in contesti sperimentali, non sono ancora ottimizzati per l’uso in tempo reale o per interagire con i sistemi informativi ospedalieri. Infine, la mancanza di interpretabilità delle predizioni rimane un ostacolo significativo per l’adozione clinica, poiché i medici necessitano di comprendere le basi delle decisioni algoritmiche.

Questo contesto evidenzia l’importanza di sviluppare soluzioni innovative che affrontino non solo gli aspetti tecnici della segmentazione, ma anche le esigenze pratiche degli operatori sanitari. La pipeline proposta in questo lavoro si inserisce proprio in questo spazio, cercando di colmare alcune delle lacune esistenti attraverso un approccio bilanciato tra accuratezza, efficienza e adattabilità.