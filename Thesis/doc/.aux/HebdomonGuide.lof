\babel@toc {italian}{}\relax 
\babel@toc {italian}{}\relax 
\addvspace {10\p@ }
\contentsline {xchapter}{\textcolor {mciBlue}{Introduzione}}{4}{chapter.1}%
\contentsline {figure}{\numberline {1.1}{\ignorespaces Immagine 3D di un cervello catturata tramite una MRI. \blx@tocontentsinit {0}\cite {brain_mri_3d}}}{4}{figure.caption.2}%
\contentsline {figure}{\numberline {1.2}{\ignorespaces Logo PyTorch. \blx@tocontentsinit {0}\cite {pytorch_logo}}}{5}{figure.caption.3}%
\contentsline {figure}{\numberline {1.3}{\ignorespaces Esempio di output del comando \texttt {nvidia-smi} per monitorare le GPU disponibili.}}{6}{figure.caption.4}%
\addvspace {10\p@ }
\contentsline {xchapter}{\textcolor {mciBlue}{Background e Stato dell'Arte}}{7}{chapter.2}%
\contentsline {figure}{\numberline {2.1}{\ignorespaces Outer surface segmentation of breast MRI image. \blx@tocontentsinit {0}\cite {breast_mri_3d}}}{8}{figure.caption.5}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces Schema concettuale dell'architettura U-Net.}}{9}{figure.caption.6}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces Overview dei dati di input e la U-NET usata per la segmentazione del seno.}}{10}{figure.caption.7}%
\addvspace {10\p@ }
\contentsline {xchapter}{\textcolor {mciBlue}{Dataset: Duke Breast Cancer MRI}}{12}{chapter.3}%
\contentsline {figure}{\numberline {3.1}{\ignorespaces Fast Breast MRI Available to Women with Average Breast Cancer Risk | Duke Health \blx@tocontentsinit {0}\cite {mri_machine}}}{12}{figure.caption.8}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces Grafico a torta della suddivisione del dataset}}{13}{figure.caption.9}%
\addvspace {10\p@ }
\contentsline {xchapter}{\textcolor {mciBlue}{Configurazione Sperimentale}}{14}{chapter.4}%
\addvspace {10\p@ }
\contentsline {xchapter}{\textcolor {mciBlue}{Esperimenti}}{19}{chapter.5}%
\contentsline {figure}{\numberline {5.1}{\ignorespaces Andamento del learning rate durante il training, con warmup iniziale e successiva discesa coseno.}}{22}{figure.caption.14}%
\contentsline {figure}{\numberline {5.2}{\ignorespaces Shcema dell’Attention U-Net. Le frecce indicano il flusso di informazioni tra i moduli di encoder e decoder, con l’integrazione del modulo di attenzione.}}{25}{figure.caption.17}%
\contentsline {figure}{\numberline {5.3}{\ignorespaces Andamento delle funzioni di loss durante il training dell’esperimento finale(EXP 21).}}{26}{figure.caption.18}%
\contentsline {figure}{\numberline {5.4}{\ignorespaces Andamento delle metriche di valutazione durante il training dell’esperimento finale(EXP 21).}}{26}{figure.caption.19}%
\contentsline {figure}{\numberline {5.5}{\ignorespaces Esempi di segmentazione ottenuti con il modello finale (EXP 21). Le immagini mostrano le predizioni su diverse slice del test set, evidenziando la capacità del modello di identificare correttamente le aree di interesse.}}{27}{figure.caption.21}%
\contentsline {figure}{\numberline {5.6}{\ignorespaces Esempio di segmentazione prima e dopo l'applicazione del closing morfologico. Le immagini mostrano come il closing migliori la coesione delle strutture segmentate, eliminando piccole discontinuità e rendendo le maschere più uniformi.}}{28}{figure.caption.22}%
\addvspace {10\p@ }
\contentsline {xchapter}{\textcolor {mciBlue}{Conclusioni}}{30}{chapter.6}%
\addvspace {10\p@ }
\contentsline {xchapter}{Bibliografia}{35}{chapter*.25}%
\providecommand \tocbasic@end@toc@file {}\tocbasic@end@toc@file 
